{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5009b566",
   "metadata": {},
   "outputs": [],
   "source": [
    "import google.generativeai as genai\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import random\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6b0b1c6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API key loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "load_dotenv()  # Load API key from .env\n",
    "\n",
    "GEMINI_API_KEY = os.getenv(\"GEMINI_API_KEY\")\n",
    "\n",
    "if GEMINI_API_KEY:\n",
    "    print(\"API key loaded successfully!\")\n",
    "else:\n",
    "    print(\"Failed to load API key. Check .env file.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "74633ad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "genai.configure(api_key=GEMINI_API_KEY)\n",
    "\n",
    "# Ask the user for custom themes\n",
    "#themes = input(\"Select themes for the quiz (e.g., space travel, medieval duels, cooking disasters): \").strip()\n",
    "themes = input(\"Select themes for the quiz. Can be your hobbies, situations, or anything else\").strip()\n",
    "\n",
    "if not themes:\n",
    "    print(\"No themes entered! Defaulting to 'random absurdity'.\")\n",
    "    themes = \"random absurdity\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2e9ad171",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_scenario_and_actions(themes):\n",
    "    prompt = f\"\"\"\n",
    "    Pick ONE of the following themes: {themes}.\n",
    "    Create a funny or dramatic situation based on this themes.\n",
    "    The situation should require a decision from me. Use no more than 50 words.\n",
    "    The situation should be different to any of the previous ones generated.\n",
    "    Provide two possible actions I can take. Make the options interesting and different from each other, so that it is telling of my personality.\n",
    "    \n",
    "    Example situation:\n",
    "    \"You're facing a major dilema that requires you to act quickly. What are you more likely to do?\"\n",
    "\n",
    "    Format the response like this:\n",
    "    ---\n",
    "    Situation: [Generated situation]\n",
    "    \n",
    "    1. [First action]\n",
    "    2. [Second action]\n",
    "    ---\n",
    "    \"\"\"\n",
    "\n",
    "    model = genai.GenerativeModel(\"gemini-1.5-flash\")\n",
    "    response = model.generate_content(prompt)\n",
    "    \n",
    "    return response.text.strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "272cfe3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Let's learn a little about who you are\n",
      "\n",
      "\n",
      "Round 1\n",
      "\n",
      "Situation:  You're in a Belgian hospital, desperately needing a waffle, but the vending machine only takes 2 Euro coins, and you only have a crumpled 50 Euro note.\n",
      "\n",
      "1.  Attempt to politely negotiate a waffle exchange with the stern-faced nurse.\n",
      "2.  Discreetly try to locate a nearby money exchange, risking missing your crucial waffle window.\n",
      "\n",
      "Quiz complete! Analyzing your personality...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Store user choices\n",
    "user_choices = []\n",
    "user_avoided = []\n",
    "\n",
    "print(\"\\nLet's learn a little about who you are\\n\")\n",
    "\n",
    "for round_num in range(2):\n",
    "    print(f\"\\nRound {round_num + 1}\")\n",
    "\n",
    "    # Get AI-generated scenario and actions\n",
    "    scenario_output = generate_scenario_and_actions(themes)\n",
    "    lines = scenario_output.split(\"\\n\")\n",
    "    \n",
    "    # Filter out empty lines and lines with length <= 3\n",
    "    filtered_lines = [line for line in lines if len(line.strip()) > 3]\n",
    "\n",
    "    situation = filtered_lines[0].strip()\n",
    "    action_1 = filtered_lines[1].strip()\n",
    "    action_2 = filtered_lines[2].strip()\n",
    "\n",
    "    print(f\"\\n{situation}\\n\")\n",
    "    print(f\"{action_1}\")\n",
    "    print(f\"{action_2}\")\n",
    "\n",
    "    choice = input(\"Pick an option (1/2): \").strip()\n",
    "    if choice not in [\"1\", \"2\"]:\n",
    "        print(\"Invalid choice! Choosing randomly for you...\")\n",
    "        choice = str(random.choice([\"1\", \"2\"]))\n",
    "\n",
    "    user_choices.append(action_1 if choice == \"1\" else action_2)\n",
    "    user_avoided.append(action_2 if choice == \"1\" else action_1)\n",
    "\n",
    "print(\"\\nQuiz complete! Analyzing your personality...\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97a081e0",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "analyse_personality() missing 1 required positional argument: 'avoided'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 15\u001b[0m\n\u001b[0;32m     12\u001b[0m     response \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mgenerate_content(prompt)\n\u001b[0;32m     13\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\u001b[38;5;241m.\u001b[39mtext\u001b[38;5;241m.\u001b[39mstrip()\n\u001b[1;32m---> 15\u001b[0m personality_summary \u001b[38;5;241m=\u001b[39m \u001b[43manalyse_personality\u001b[49m\u001b[43m(\u001b[49m\u001b[43muser_choices\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPersonality Summary: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpersonality_summary\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mTypeError\u001b[0m: analyse_personality() missing 1 required positional argument: 'avoided'"
     ]
    }
   ],
   "source": [
    "def analyse_personality(choices, avoided):\n",
    "    prompt = f\"\"\"\n",
    "    This is a list of actions I have chosen to take: {choices}\n",
    "\n",
    "    While this is a list of actions I have avoided: {avoided}\n",
    "    I want you to analyze my personality based on these choices and avoided actions.\n",
    "\n",
    "    Write 2-3 sentences summarising my personality in an engaging way. You can be roast me and be savage.\n",
    "    \"\"\"\n",
    "\n",
    "    model = genai.GenerativeModel(\"gemini-1.5-flash\")\n",
    "    response = model.generate_content(prompt)\n",
    "    return response.text.strip()\n",
    "\n",
    "personality_summary = analyse_personality(user_choices, user_avoided)\n",
    "\n",
    "print(f\"Personality Summary: {personality_summary}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
